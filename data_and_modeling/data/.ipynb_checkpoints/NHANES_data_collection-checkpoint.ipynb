{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLLECTION OF NATIONAL HEALTH & NUTRITION EXAMINATION SURVEY DATA FOR PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worksheet is used for collecting, combining, and filtering of data from the National Health & Nutrition Examination Survey.\n",
    "Data is posted in XPT format in two-year increments for various topics related to the survey.  Data was collected for 1999-2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note on the data: NHANES sample weights are used by analysts to produce estimates of the health-related statistics that would have been obtained if the entire sampling frame (i.e., the noninstitutionalized civilian U.S. population) had been surveyed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KEY:\n",
    "Key for letters that correspond to 2-year ranges.  Letters selected for their correspondence to labeling of the years by NHANES. >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E = 2007 - 2008</br>\n",
    "F = 2009 - 2010</br>\n",
    "G = 2011 - 2012</br>\n",
    "H = 2013 - 2014</br>\n",
    "I = 2015 - 2016</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: PULLING THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E: 2007-2008 file pull and merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in XPT files to create dataframes\n",
    "\n",
    "E_blood_press = pd.read_sas('NHANES_files/blood_pressure/E_BloodPressure_BPX_E.XPT') #blood pressure (target)\n",
    "\n",
    "E_body_meas = pd.read_sas('NHANES_files/body_measures/E_BodyMeasures_BMX_E.XPT') #body measures\n",
    "\n",
    "E_diet = pd.read_sas('NHANES_files/dietary_selections/E_diet_DBQ_E.XPT') #dietary selections\n",
    "                    \n",
    "E_smoking = pd.read_sas('NHANES_files/smoking_status/E_smoking_SMQ_E.XPT') #smoking status\n",
    "\n",
    "E_physical_act = pd.read_sas('NHANES_files/physical_activity/E_physical_act_PAQ_E.XPT') #physical activity\n",
    "\n",
    "E_age_gender_race = pd.read_sas('NHANES_files/age_gender_race/E_demographic_DEMO_E.XPT') #age, gender, & race\n",
    "\n",
    "E_alcohol = pd.read_sas('NHANES_files/alcohol_consumption/E_alcohol_ALQ_E.XPT') #alcohol consumption\n",
    "\n",
    "E_medical_cond = pd.read_sas('NHANES_files/medical_conditions/E_med_con_MCQ_E.XPT') #medical conditions\n",
    "\n",
    "E_work_info = pd.read_sas('NHANES_files/work_info/E_work_OCQ_E.XPT') #work info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lists together on each respondents 'sequence number'\n",
    "\n",
    "E_merged_total = reduce(lambda x,y: pd.merge(x,y, on='SEQN', how='outer'),\n",
    "                        [E_blood_press, E_body_meas,\n",
    "                         E_diet, E_smoking, E_physical_act,\n",
    "                         E_age_gender_race, E_alcohol,\n",
    "                         E_medical_cond, E_work_info,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrow df to only the features & target we want to explor for model\n",
    "\n",
    "E_filtered = E_merged_total[[\"SEQN\",\"BPXSY1\",\"BPXSY2\",\"BPXSY3\",\n",
    "                             \"BPXDI1\",\"BPXDI2\",\"BPXDI3\",\n",
    "                             \"BMXBMI\",\"BMXWAIST\",\"BMXHT\",\n",
    "                             \"BMXWT\", \"DBD895\",\"DBD905\",\n",
    "                             \"DBD910\",\"SMQ020\",\"SMQ040\",\n",
    "                             \"PAQ605\",\"PAQ620\",\"PAQ635\",\n",
    "                             \"PAQ650\",\"PAD680\",\"RIAGENDR\",\n",
    "                             \"RIDAGEYR\",\"RIDRETH1\",\n",
    "                             \"ALQ101\",\"ALQ120U\",\"OCD150\",\n",
    "                             \"OCQ180\",\n",
    "                            ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F: 2009-2010 file pull and merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in XPT files to create dataframes\n",
    "\n",
    "F_blood_press = pd.read_sas('NHANES_files/blood_pressure/F_BloodPressure_BPX_F.XPT') #blood pressure (target)\n",
    "\n",
    "F_body_meas = pd.read_sas('NHANES_files/body_measures/F_BodyMeasures_BMX_F.XPT') #body measures\n",
    "\n",
    "F_diet = pd.read_sas('NHANES_files/dietary_selections/F_diet_DBQ_F.XPT') #dietary selections\n",
    "                    \n",
    "F_smoking = pd.read_sas('NHANES_files/smoking_status/F_smoking_SMQ_F.XPT') #smoking status\n",
    "\n",
    "F_physical_act = pd.read_sas('NHANES_files/physical_activity/F_physical_act_PAQ_F.XPT') #physical activity\n",
    "\n",
    "F_age_gender_race = pd.read_sas('NHANES_files/age_gender_race/F_demographic_DEMO_F.XPT') #age, gender, & race\n",
    "\n",
    "F_alcohol = pd.read_sas('NHANES_files/alcohol_consumption/F_alcohol_ALQ_F.XPT') #alcohol consumption\n",
    "\n",
    "F_medical_cond = pd.read_sas('NHANES_files/medical_conditions/F_med_con_MCQ_F.XPT') #medical conditions\n",
    "\n",
    "F_work_info = pd.read_sas('NHANES_files/work_info/F_work_OCQ_F.XPT') #work info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lists together on each respondents 'sequence number'\n",
    "\n",
    "F_merged_total = reduce(lambda x,y: pd.merge(x,y, on='SEQN', how='outer'),\n",
    "                        [F_blood_press, F_body_meas,\n",
    "                         F_diet, F_smoking, F_physical_act,\n",
    "                         F_age_gender_race, F_alcohol,\n",
    "                         F_medical_cond, F_work_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>PEASCST1</th>\n",
       "      <th>PEASCTM1</th>\n",
       "      <th>PEASCCT1</th>\n",
       "      <th>BPXCHR</th>\n",
       "      <th>BPQ150A</th>\n",
       "      <th>BPQ150B</th>\n",
       "      <th>BPQ150C</th>\n",
       "      <th>BPQ150D</th>\n",
       "      <th>BPAARM</th>\n",
       "      <th>...</th>\n",
       "      <th>OCD392</th>\n",
       "      <th>OCD395</th>\n",
       "      <th>OCQ510</th>\n",
       "      <th>OCQ520</th>\n",
       "      <th>OCQ530</th>\n",
       "      <th>OCQ540</th>\n",
       "      <th>OCQ550</th>\n",
       "      <th>OCQ560</th>\n",
       "      <th>OCQ570</th>\n",
       "      <th>OCQ580</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51624.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51625.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51626.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51628.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN  PEASCST1  PEASCTM1  PEASCCT1  BPXCHR  BPQ150A  BPQ150B  BPQ150C  \\\n",
       "0  51624.0       1.0     583.0       NaN     NaN      2.0      2.0      2.0   \n",
       "1  51625.0       1.0     278.0       NaN    92.0      NaN      NaN      NaN   \n",
       "2  51626.0       1.0     689.0       NaN     NaN      1.0      2.0      2.0   \n",
       "3  51627.0       1.0     699.0       NaN     NaN      2.0      2.0      2.0   \n",
       "4  51628.0       1.0    1098.0       NaN     NaN      1.0      2.0      2.0   \n",
       "\n",
       "   BPQ150D  BPAARM  ...  OCD392  OCD395  OCQ510  OCQ520  OCQ530  OCQ540  \\\n",
       "0      2.0     1.0  ...    19.0   120.0     2.0     NaN     2.0     NaN   \n",
       "1      NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2      2.0     1.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3      2.0     1.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4      2.0     1.0  ...    21.0    60.0     1.0    38.0     1.0    38.0   \n",
       "\n",
       "   OCQ550  OCQ560  OCQ570  OCQ580  \n",
       "0     1.0     1.0     1.0     1.0  \n",
       "1     NaN     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN     NaN  \n",
       "4     1.0    38.0     1.0    38.0  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_merged_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrow df to only the features & target we want to explor for model\n",
    "\n",
    "F_filtered = F_merged_total[[\"SEQN\",\"BPXSY1\",\"BPXSY2\",\"BPXSY3\",\n",
    "                             \"BPXDI1\",\"BPXDI2\",\"BPXDI3\",\n",
    "                             \"BMXBMI\",\"BMXWAIST\",\"BMXHT\",\n",
    "                             \"BMXWT\", \"DBD895\",\"DBD905\",\n",
    "                             \"DBD910\",\"SMQ020\",\"SMQ040\",\n",
    "                             \"PAQ605\",\"PAQ620\",\"PAQ635\",\n",
    "                             \"PAQ650\",\"PAD680\",\"RIAGENDR\",\n",
    "                             \"RIDAGEYR\",\"RIDRETH1\",\n",
    "                             \"ALQ101\",\"ALQ120U\",\"OCD150\",\n",
    "                             \"OCQ180\",\n",
    "                            ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G: 2011-2012 file pull and merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in XPT files to create dataframes\n",
    "\n",
    "G_blood_press = pd.read_sas('NHANES_files/blood_pressure/G_BloodPressure_BPX_G.XPT') #blood pressure (target)\n",
    "\n",
    "G_body_meas = pd.read_sas('NHANES_files/body_measures/G_BodyMeasures_BMX_G.XPT') #body measures\n",
    "\n",
    "G_diet = pd.read_sas('NHANES_files/dietary_selections/G_diet_DBQ_G.XPT') #dietary selections\n",
    "                    \n",
    "G_smoking = pd.read_sas('NHANES_files/smoking_status/G_smoking_SMQ_G.XPT') #smoking status\n",
    "\n",
    "G_physical_act = pd.read_sas('NHANES_files/physical_activity/G_physical_act_PAQ_G.XPT') #physical activity\n",
    "\n",
    "G_age_gender_race = pd.read_sas('NHANES_files/age_gender_race/G_demographic_DEMO_G.XPT') #age, gender, & race\n",
    "\n",
    "G_alcohol = pd.read_sas('NHANES_files/alcohol_consumption/G_alcohol_ALQ_G.XPT') #alcohol consumption\n",
    "\n",
    "G_medical_cond = pd.read_sas('NHANES_files/medical_conditions/G_med_con_MCQ_G.XPT') #medical conditions\n",
    "\n",
    "G_work_info = pd.read_sas('NHANES_files/work_info/G_work_OCQ_G.XPT') #work info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lists together on each respondents 'sequence number'\n",
    "\n",
    "G_merged_total = reduce(lambda x,y: pd.merge(x,y, on='SEQN', how='outer'),\n",
    "                        [G_blood_press, G_body_meas,\n",
    "                         G_diet, G_smoking, G_physical_act,\n",
    "                         G_age_gender_race, G_alcohol,\n",
    "                         G_medical_cond, G_work_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrow df to only the features & target we want to explor for model\n",
    "\n",
    "G_filtered = G_merged_total[[\"SEQN\",\"BPXSY1\",\"BPXSY2\",\"BPXSY3\",\n",
    "                             \"BPXDI1\",\"BPXDI2\",\"BPXDI3\",\n",
    "                             \"BMXBMI\",\"BMXWAIST\",\"BMXHT\",\n",
    "                             \"BMXWT\", \"DBD895\",\"DBD905\",\n",
    "                             \"DBD910\",\"SMQ020\",\"SMQ040\",\n",
    "                             \"PAQ605\",\"PAQ620\",\"PAQ635\",\n",
    "                             \"PAQ650\",\"PAD680\",\"RIAGENDR\",\n",
    "                             \"RIDAGEYR\",\"RIDRETH1\",\n",
    "                             \"ALQ101\",\"ALQ120U\",\"OCD150\",\n",
    "                             \"OCQ180\",\n",
    "                            ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H: 2013-2014 file pull and merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in XPT files to create dataframes\n",
    "\n",
    "H_blood_press = pd.read_sas('NHANES_files/blood_pressure/H_BloodPressure_BPX_H.XPT') #blood pressure (target)\n",
    "\n",
    "H_body_meas = pd.read_sas('NHANES_files/body_measures/H_BodyMeasures_BMX_H.XPT') #body measures\n",
    "\n",
    "H_diet = pd.read_sas('NHANES_files/dietary_selections/H_diet_DBQ_H.XPT') #dietary selections\n",
    "                    \n",
    "H_smoking = pd.read_sas('NHANES_files/smoking_status/H_smoking_SMQ_H.XPT') #smoking status\n",
    "\n",
    "H_physical_act = pd.read_sas('NHANES_files/physical_activity/H_physical_act_PAQ_H.XPT') #physical activity\n",
    "\n",
    "H_age_gender_race = pd.read_sas('NHANES_files/age_gender_race/H_demographic_DEMO_H.XPT') #age, gender, & race\n",
    "\n",
    "H_alcohol = pd.read_sas('NHANES_files/alcohol_consumption/H_alcohol_ALQ_H.XPT') #alcohol consumption\n",
    "\n",
    "H_medical_cond = pd.read_sas('NHANES_files/medical_conditions/H_med_con_MCQ_H.XPT') #medical conditions\n",
    "\n",
    "H_work_info = pd.read_sas('NHANES_files/work_info/H_work_OCQ_H.XPT') #work info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lists together on each respondents 'sequence number'\n",
    "\n",
    "H_merged_total = reduce(lambda x,y: pd.merge(x,y, on='SEQN', how='outer'),\n",
    "                        [H_blood_press, H_body_meas,\n",
    "                         H_diet, H_smoking, H_physical_act,\n",
    "                         H_age_gender_race, H_alcohol,\n",
    "                         H_medical_cond, H_work_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_filtered = H_merged_total[[\"SEQN\",\"BPXSY1\",\"BPXSY2\",\"BPXSY3\",\n",
    "                             \"BPXDI1\",\"BPXDI2\",\"BPXDI3\",\n",
    "                             \"BMXBMI\",\"BMXWAIST\",\"BMXHT\",\n",
    "                             \"BMXWT\", \"DBD895\",\"DBD905\",\n",
    "                             \"DBD910\",\"SMQ020\",\"SMQ040\",\n",
    "                             \"PAQ605\",\"PAQ620\",\"PAQ635\",\n",
    "                             \"PAQ650\",\"PAD680\",\"RIAGENDR\",\n",
    "                             \"RIDAGEYR\",\"RIDRETH1\",\n",
    "                             \"ALQ101\",\"ALQ120U\",\"OCD150\",\n",
    "                             \"OCQ180\",\n",
    "                            ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I: 2015-2016 file pull and merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in XPT files to create dataframes\n",
    "\n",
    "I_blood_press = pd.read_sas('NHANES_files/blood_pressure/I_BloodPressure_BPX_I.XPT') #blood pressure (target)\n",
    "\n",
    "I_body_meas = pd.read_sas('NHANES_files/body_measures/I_BodyMeasures_BMX_I.XPT') #body measures\n",
    "\n",
    "I_diet = pd.read_sas('NHANES_files/dietary_selections/I_diet_DBQ_I.XPT') #dietary selections\n",
    "                    \n",
    "I_smoking = pd.read_sas('NHANES_files/smoking_status/I_smoking_SMQ_I.XPT') #smoking status\n",
    "\n",
    "I_physical_act = pd.read_sas('NHANES_files/physical_activity/I_physical_act_PAQ_I.XPT') #physical activity\n",
    "\n",
    "I_age_gender_race = pd.read_sas('NHANES_files/age_gender_race/I_demographic_DEMO_I.XPT') #age, gender, & race\n",
    "\n",
    "I_alcohol = pd.read_sas('NHANES_files/alcohol_consumption/I_alcohol_ALQ_I.XPT') #alcohol consumption\n",
    "\n",
    "I_medical_cond = pd.read_sas('NHANES_files/medical_conditions/I_med_con_MCQ_I.XPT') #medical conditions\n",
    "\n",
    "I_work_info = pd.read_sas('NHANES_files/work_info/I_work_OCQ_I.XPT') #work info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lists together on each respondents 'sequence number'\n",
    "\n",
    "I_merged_total = reduce(lambda x,y: pd.merge(x,y, on='SEQN', how='outer'),\n",
    "                        [I_blood_press, I_body_meas,\n",
    "                         I_diet, I_smoking, I_physical_act,\n",
    "                         I_age_gender_race, I_alcohol,\n",
    "                         I_medical_cond, I_work_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_filtered = I_merged_total[[\"SEQN\",\"BPXSY1\",\"BPXSY2\",\"BPXSY3\",\n",
    "                             \"BPXDI1\",\"BPXDI2\",\"BPXDI3\",\n",
    "                             \"BMXBMI\",\"BMXWAIST\",\"BMXHT\",\n",
    "                             \"BMXWT\", \"DBD895\",\"DBD905\",\n",
    "                             \"DBD910\",\"SMQ020\",\"SMQ040\",\n",
    "                             \"PAQ605\",\"PAQ620\",\"PAQ635\",\n",
    "                             \"PAQ650\",\"PAD680\",\"RIAGENDR\",\n",
    "                             \"RIDAGEYR\",\"RIDRETH1\",\n",
    "                             \"ALQ101\",\"ALQ120U\",\"OCD150\",\n",
    "                             \"OCQ180\",\n",
    "                            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: CREATE MASTER LIST\n",
    "Now combine all 2-year dataframes created above and clean up the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack all of the dataframes >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.concat([E_filtered, F_filtered,\n",
    "                          G_filtered, H_filtered,\n",
    "                          I_filtered],\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pickle the full dataset to save >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/full_dataset.pickle', 'wb') as to_write:\n",
    "    pickle.dump(full_dataset, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now un-pickle to work with full dataset >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/full_dataset.pickle','rb') as read_file:\n",
    "    nhanes_data = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's clean up the dataset >\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhanes_data.rename(columns={\"SEQN\":\"Patient_ID\",\n",
    "                            \"BPXSY1\": \"Systolic_1Rd\",\n",
    "                            \"BPXSY2\": \"Systolic_2Rd\",\n",
    "                            \"BPXSY3\": \"Systolic_3Rd\",\n",
    "                            \"BPXDI1\": \"Diastolic_1Rd\",\n",
    "                            \"BPXDI2\": \"Diastolic_2Rd\",\n",
    "                            \"BPXDI3\": \"Diastolic_3Rd\",\n",
    "                            \"BMXBMI\": \"BMI\",\n",
    "                            \"BMXWAIST\": \"Waist_Circum\",\n",
    "                            \"BMXHT\": \"Height\",\n",
    "                            \"BMXWT\": \"Weight\",\n",
    "                            \"DBD895\": \"Eat_Out\",\n",
    "                            \"DBD905\": \"Ready_to_Eat\",\n",
    "                            \"DBD910\": \"Frozen_Foods\",\n",
    "                            \"SMQ020\": \"Smoked_Hund\",\n",
    "                            \"SMQ040\": \"Curr_Smoke\",\n",
    "                            \"PAQ605\": \"Work_Vig_Act\",\n",
    "                            \"PAQ620\": \"Work_Mod_Act\",\n",
    "                            \"PAQ635\": \"Walk_Bike\",\n",
    "                            \"PAQ650\": \"Rec_Vig_Act\",\n",
    "                            \"PAD680\": \"Sitting_Time\",\n",
    "                            \"RIAGENDR\": \"Gender\",\n",
    "                            \"RIDAGEYR\": \"Age\",\n",
    "                            \"RIDRETH1\": \"Race\",\n",
    "                            \"ALQ101\": \"Twelve_Alcohol\",\n",
    "                            \"ALQ120U\": \"Days_Alcohol_Wk\",\n",
    "                            \"OCD150\": \"Job_Type\",\n",
    "                            \"OCQ180\": \"Num_Hrs_Worked_Wk\"\n",
    "                           }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace codes used in certain columns with applicable text >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoked over 100 times in lifetime\n",
    "# 1.0 = Yes and 2.0 = No, so changing to 1 and 0 so can work as dummy category\n",
    "\n",
    "nhanes_data['Smoked_Hund'].replace({1.0: 1, 2.0: 0}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vigorous work activity\n",
    "# 1.0 = Yes and 2.0 = No, so changing to 1 and 0 so can work as dummy category\n",
    "\n",
    "nhanes_data['Work_Vig_Act'].replace({1.0: 1, 2.0: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moderate work activity\n",
    "# 1.0 = Yes and 2.0 = No, so changing to 1 and 0 so can work as dummy category\n",
    "\n",
    "nhanes_data['Work_Mod_Act'].replace({1.0: 1, 2.0: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk or bicycle at least for 10 min continuous in typical week\n",
    "# 1.0 = Yes and 2.0 = No, so changing to 1 and 0 so can work as dummy category\n",
    "\n",
    "nhanes_data['Walk_Bike'].replace({1.0: 1, 2.0: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vigorous-intensity fitness or activities for 10 min continuous in typical week\n",
    "# 1.0 = Yes and 2.0 = No, so changing to 1 and 0 so can work as dummy category\n",
    "# also droping those that have been coded as missing or refused to answer\n",
    "\n",
    "nhanes_data['Rec_Vig_Act'].replace({1.0: 1, 2.0: 0}, inplace=True)\n",
    "\n",
    "rec_vig_indices = nhanes_data[(nhanes_data['Rec_Vig_Act'] == 9.0)\n",
    "                             ].index\n",
    "\n",
    "nhanes_data.drop(rec_vig_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sitting time\n",
    "# get rid of values that represent 'don't know' or 'missing'\n",
    "\n",
    "sit_indices = nhanes_data[(nhanes_data['Sitting_Time'] == 7777.0)\n",
    "                          | (nhanes_data['Sitting_Time'] == 9999.0)\n",
    "                         ].index\n",
    "\n",
    "nhanes_data.drop(sit_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race\n",
    "\n",
    "nhanes_data['Race'].replace({1.0: \"Mexican_American\", 2.0: \"Other_Hispanic\",\n",
    "                             3.0: \"Non_Hispanic_White\", 4.0: \"Non_Hispanic_Black\",\n",
    "                             5.0: \"Other_Race\"\n",
    "                            }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eating out\n",
    "# category uses extremely low number for 'none' -- replaced with 0\n",
    "\n",
    "nhanes_data['Eat_Out'].replace({5.397605346934028e-79: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready-to-eat\n",
    "# category uses extremely low number for 'none' -- replaced with 0\n",
    "\n",
    "nhanes_data['Ready_to_Eat'].replace({5.397605346934028e-79: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozen foods\n",
    "# category uses extremely low number for 'none' -- replaced with 0\n",
    "nhanes_data['Frozen_Foods'].replace({5.397605346934028e-79: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1380.0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(nhanes_data['Sitting_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES FOR HOW TO \"CLEAN\" UP BLOOD PRESSURE DATA & THEN CREATE Y VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all of the rows with null values\n",
    "\n",
    "test_blood_pressure_nonull = test_blood_pressure.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for all mean of diastolic readings\n",
    "\n",
    "test_blood_pressure_nonull['Systolic_Avg'] = test_blood_pressure_nonull[\n",
    "    ['Systolic_Rd1', 'Systolic_Rd2','Systolic_Rd3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for all mean of diastolic readings\n",
    "\n",
    "test_blood_pressure_nonull['Diastolic_Avg'] = test_blood_pressure_nonull[\n",
    "    ['Diastolic_Rd1', 'Diastolic_Rd2','Diastolic_Rd3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine whether person has high blood pressure\n",
    "\n",
    "def blood_pressure_status(row):\n",
    "    if row['Systolic_Avg'] > 130 or row['Diastolic_Avg'] > 80:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application of above function to run through entire dataframe\n",
    "\n",
    "test_blood_pressure_nonull['High_Blood_Pressure'] = test_blood_pressure_nonull.apply(\n",
    "    lambda row: blood_pressure_status(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7762\n",
       "1    3032\n",
       "Name: High_Blood_Pressure, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many have high blood pressure in the data set (1 = high blood pressure)\n",
    "\n",
    "test_blood_pressure_nonull.High_Blood_Pressure.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
